{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_test_script.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzqqcWC-cZfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from attention import AttentionLayer\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "with open('var.pickle','rb') as f:\n",
        "  char_indices,eng_char_indices,to_ts,from_ts= pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iBMEXZwe1tQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def value_to_key(search,word_index):\n",
        "  for word, num in word_index.items():   \n",
        "    if num == search:\n",
        "        return word\n",
        "      \n",
        "def char_to_sequences(x,char_indices):\n",
        "  for sen in x:\n",
        "    seq = []\n",
        "    for char in sen:\n",
        "      seq.append(char_indices[char])    \n",
        "    yield seq\n",
        "def sequences_to_texts(texts, word_index):\n",
        "    for tokens in texts:\n",
        "        temp = []\n",
        "        for w in tokens:\n",
        "          temp.append(value_to_key(w,word_index))\n",
        "        yield temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d68bc0fe-e9e7-433c-d713-34b31ba31ddc",
        "id": "SkLUIqTfT3GC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "encoder_model = load_model(\"encoder_model.h5\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpcCmw7EUTOY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d300ef55-b589-4656-fdb0-4c641afd70b6"
      },
      "source": [
        "decoder_model = load_model(\"decoder_model.h5\",custom_objects={\"AttentionLayer\":AttentionLayer})"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvsSYvSMfKXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def predict(word):\n",
        "  word = list(char_to_sequences([word],char_indices))\n",
        "  word = pad_sequences(word, padding=\"pre\", maxlen=from_ts)\n",
        "\n",
        "  \n",
        "\n",
        "  test_from = word[0]\n",
        "  test_from = test_from.reshape(1,test_from.shape[0])\n",
        "  \n",
        "  test_to = list(char_to_sequences([\"*\"],eng_char_indices))\n",
        "  test_to = np.array(test_to)\n",
        "  test_to = test_to.reshape(1,test_to.shape[0])\n",
        "\n",
        "\n",
        "  enc_outs, enc_fwd_state, enc_back_state = encoder_model.predict([test_from])\n",
        "  dec_state = np.concatenate([enc_fwd_state, enc_back_state], axis=-1)\n",
        "  attention_weights = []\n",
        "  to_text = []\n",
        "\n",
        "  for i in range(to_ts):\n",
        "    \n",
        "    dec_out, attention, dec_state = decoder_model.predict([enc_outs, dec_state, test_to])\n",
        "    dec_ind = np.argmax(dec_out, axis=-1)[0, 0]\n",
        "    end = eng_char_indices[\"*\"]\n",
        "    if dec_ind == end:\n",
        "        break\n",
        "    test_to = [[dec_ind]]\n",
        "    test_to = np.array(test_to)\n",
        "    test_to = test_to.reshape(1,test_to.shape[0])\n",
        "\n",
        "    attention_weights.append((dec_ind, attention))\n",
        "    to_text.append(dec_ind)\n",
        "    result = list(sequences_to_texts([to_text],eng_char_indices))[0]\n",
        "    predicted_res = str(\"\".join(result)).strip()\n",
        "\n",
        "  return predicted_res\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KojfsmZvhDVx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27aa3dfe-9aec-4ed3-febb-27e97eedf013"
      },
      "source": [
        "predict(\"इन्साइक्लपीडीअ\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'insiclapidy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3CsE8lTa_bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}